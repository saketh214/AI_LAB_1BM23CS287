{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClehkGyi7JnB",
        "outputId": "927ca59c-5b02-4f53-cc25-1578714099a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B | A | C  |  B -> A  |  A -> C  |  B  |  C\n",
            "-------------------------------------------\n",
            "F | F | F  |  T | T | F  |  F\n",
            "F | F | T  |  T | T | F  |  T\n",
            "F | T | F  |  T | F | F  |  F\n",
            "F | T | T  |  T | T | F  |  T\n",
            "T | F | F  |  F | T | T  |  F\n",
            "T | F | T  |  F | T | T  |  T\n",
            "T | T | F  |  T | F | T  |  F\n",
            "T | T | T  |  T | T | T  |  T\n",
            "\n",
            "Models where KB is true:\n",
            "  B=T, A=T, C=T  (Query=T)\n",
            "\n",
            "Entailment result:\n",
            "  KB ⊨ query  — query is entailed by KB.\n",
            "\n",
            "Final answer: True\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "import re\n",
        "\n",
        "# ---- Parser / evaluator utilities ----\n",
        "\n",
        "def tokenize(formula):\n",
        "    \"\"\"Turn formula string into tokens.\"\"\"\n",
        "    # normalize spaces\n",
        "    s = formula.replace(\" \", \"\")\n",
        "    # token patterns: symbols (letters+digits+_), parentheses, operators ->, <->, ~, &, |\n",
        "    token_spec = r\"(<->|->|~|\\(|\\)|&|\\||[A-Za-z_][A-Za-z0-9_]*)\"\n",
        "    tokens = re.findall(token_spec, s)\n",
        "    if \"\".join(tokens) != s:\n",
        "        raise ValueError(f\"Failed to tokenize formula: {formula!r}\")\n",
        "    return tokens\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    \"\"\"\n",
        "    Shunting-yard algorithm supporting unary ~, binary &, |, ->, <->.\n",
        "    Precedence (high to low): ~ , & , | , -> , <->\n",
        "    Associativity: ~ (right/unary), & left, | left, -> right, <-> left\n",
        "    \"\"\"\n",
        "    prec = {'~': 5, '&': 4, '|': 3, '->': 2, '<->': 1}\n",
        "    assoc = {'~': 'right', '&': 'left', '|': 'left', '->': 'right', '<->': 'left'}\n",
        "    output = []\n",
        "    stack = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        t = tokens[i]\n",
        "        if re.fullmatch(r\"[A-Za-z_][A-Za-z0-9_]*\", t):  # symbol\n",
        "            output.append(t)\n",
        "        elif t == '(':\n",
        "            stack.append(t)\n",
        "        elif t == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            if not stack:\n",
        "                raise ValueError(\"Mismatched parentheses\")\n",
        "            stack.pop()  # pop '('\n",
        "        else:  # operator\n",
        "            # handle unary ~: when token is ~ it's unary; that's fine\n",
        "            while stack and stack[-1] != '(':\n",
        "                top = stack[-1]\n",
        "                if ((assoc[t] == 'left' and prec[t] <= prec[top]) or\n",
        "                    (assoc[t] == 'right' and prec[t] < prec[top])):\n",
        "                    output.append(stack.pop())\n",
        "                else:\n",
        "                    break\n",
        "            stack.append(t)\n",
        "        i += 1\n",
        "    while stack:\n",
        "        if stack[-1] in ('(', ')'):\n",
        "            raise ValueError(\"Mismatched parentheses\")\n",
        "        output.append(stack.pop())\n",
        "    return output\n",
        "\n",
        "def eval_postfix(postfix, model):\n",
        "    \"\"\"Evaluate postfix expression given model: dict symbol->bool\"\"\"\n",
        "    def implies(p, q):\n",
        "        return (not p) or q\n",
        "    def bicond(p, q):\n",
        "        return p == q\n",
        "\n",
        "    stack = []\n",
        "    for tok in postfix:\n",
        "        if re.fullmatch(r\"[A-Za-z_][A-Za-z0-9_]*\", tok):\n",
        "            if tok not in model:\n",
        "                raise KeyError(f\"Symbol {tok} not in model\")\n",
        "            stack.append(bool(model[tok]))\n",
        "        elif tok == '~':\n",
        "            if not stack:\n",
        "                raise ValueError(\"Bad syntax: unary operator with empty stack\")\n",
        "            v = stack.pop()\n",
        "            stack.append(not v)\n",
        "        else:\n",
        "            # binary op\n",
        "            if len(stack) < 2:\n",
        "                raise ValueError(\"Bad syntax: binary operator with insufficient operands\")\n",
        "            b = stack.pop()\n",
        "            a = stack.pop()\n",
        "            if tok == '&':\n",
        "                stack.append(a and b)\n",
        "            elif tok == '|':\n",
        "                stack.append(a or b)\n",
        "            elif tok == '->':\n",
        "                stack.append(implies(a, b))\n",
        "            elif tok == '<->':\n",
        "                stack.append(bicond(a, b))\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown operator {tok}\")\n",
        "    if len(stack) != 1:\n",
        "        raise ValueError(\"Bad syntax: leftover stack after evaluation\")\n",
        "    return stack[0]\n",
        "\n",
        "def parse_formula(formula):\n",
        "    \"\"\"Tokenize and convert to postfix once (for efficiency).\"\"\"\n",
        "    tokens = tokenize(formula)\n",
        "    postfix = infix_to_postfix(tokens)\n",
        "    return postfix\n",
        "\n",
        "# ---- Main entailment checker ----\n",
        "\n",
        "def check_entailment(symbols, kb_formulas, query_formula, verbose=True):\n",
        "    \"\"\"\n",
        "    Check whether KB entails query by enumerating all models (truth table).\n",
        "    symbols: list of symbol names (strings)\n",
        "    kb_formulas: list of formula strings (KB sentences)\n",
        "    query_formula: formula string\n",
        "    Returns: True if KB |= query, False otherwise.\n",
        "    \"\"\"\n",
        "    # parse formulas to postfix once\n",
        "    kb_postfix = [parse_formula(f) for f in kb_formulas]\n",
        "    query_postfix = parse_formula(query_formula)\n",
        "\n",
        "    rows = []\n",
        "    if verbose:\n",
        "        header = f\"{' | '.join(symbols)}  |  \" + \"  |  \".join([f\"{f}\" for f in kb_formulas]) + \"  |  \" + query_formula\n",
        "        print(header)\n",
        "        print(\"-\" * len(header))\n",
        "\n",
        "    # iterate models\n",
        "    for vals in product([False, True], repeat=len(symbols)):\n",
        "        model = dict(zip(symbols, vals))\n",
        "        # evaluate KB sentences\n",
        "        kb_values = [eval_postfix(pf, model) for pf in kb_postfix]\n",
        "        kb_true = all(kb_values)\n",
        "        query_value = eval_postfix(query_postfix, model)\n",
        "        rows.append((model, kb_values, kb_true, query_value))\n",
        "        if verbose:\n",
        "            sym_vals = \" | \".join('T' if model[s] else 'F' for s in symbols)\n",
        "            kb_vals_str = \" | \".join('T' if v else 'F' for v in kb_values)\n",
        "            qstr = 'T' if query_value else 'F'\n",
        "            print(f\"{sym_vals}  |  {kb_vals_str}  |  {qstr}\")\n",
        "\n",
        "    # collect models where KB is true\n",
        "    kb_models = [r for r in rows if r[2]]\n",
        "    if verbose:\n",
        "        print(\"\\nModels where KB is true:\")\n",
        "        if not kb_models:\n",
        "            print(\"  (none) -- KB is unsatisfiable\")\n",
        "        else:\n",
        "            for mod, kbvals, _, qv in kb_models:\n",
        "                mv = \", \".join(f\"{k}={'T' if v else 'F'}\" for k, v in mod.items())\n",
        "                print(f\"  {mv}  (Query={ 'T' if qv else 'F' })\")\n",
        "\n",
        "    # entailment: query true in all KB models\n",
        "    if not kb_models:\n",
        "        # By classical logic, unsatisfiable KB entails every formula (vacuous truth).\n",
        "        entailed = True\n",
        "    else:\n",
        "        entailed = all(r[3] for r in kb_models)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nEntailment result:\")\n",
        "        if entailed:\n",
        "            print(\"  KB ⊨ query  — query is entailed by KB.\")\n",
        "        else:\n",
        "            print(\"  KB ⊭ query  — query is NOT entailed by KB (countermodel exists).\")\n",
        "\n",
        "    return entailed\n",
        "\n",
        "# ---- Example: use the burglary example from your prompt ----\n",
        "if __name__ == \"__main__\":\n",
        "    symbols = ['B', 'A', 'C']\n",
        "    KB = [\"B -> A\", \"A -> C\", \"B\"]\n",
        "    query = \"C\"\n",
        "    result = check_entailment(symbols, KB, query, verbose=True)\n",
        "    print(\"\\nFinal answer:\", result)\n"
      ]
    }
  ]
}